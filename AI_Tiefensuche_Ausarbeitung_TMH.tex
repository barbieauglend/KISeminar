\documentclass[fleqn]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath,amsfonts,amsthm,graphicx}
\usepackage{sectsty}
\usepackage{booktabs}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{listings}
\usepackage{tikz, pgf}
\usepackage{float}

\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}

\usetikzlibrary{arrows, calc}

\tikzset{
  treenode/.style = {align=center, inner sep=0pt, text centered,
    font=\sffamily},
  arn_n/.style = {treenode, circle, white, font=\sffamily\bfseries, draw=black,
    fill=black, text width=1.5em},% arbre rouge noir, noeud noir
  arn_r/.style = {treenode, circle, red, draw=red,
    text width=1.5em, very thick},% arbre rouge noir, noeud rouge
  arn_x/.style = {treenode, rectangle, draw=black,
    minimum width=0.5em, minimum height=0.5em}% arbre rouge noir, nil
}

\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}

\renewcommand{\thesubsubsection}{(\alph{subsubsection})}

\title{Überblick Künstliche Intelligenz}
\author{Thaís Moreira Hamasaki}
\date{\today}

\begin{document}
  \lstset{language=Haskell,frame=single,basicstyle=\small\ttfamily,numbers=left,firstnumber=1}
  \lstset{language=Prolog,frame=single,basicstyle=\small\ttfamily,numbers=left,firstnumber=1}

\maketitle
\newpage

\tableofcontents
\newpage

\section{Motivation}

Die Hauptaufgabe von Rechnern ist, Probleme zu lösen. Oft kann man die Probleme graphisch darstellen, mit einem Start- und einem Zielknoten und die Wege zwichen den beiden. Hierfür benötigt man nicht nur eine Darstellung des aktuellen Zustandes sondern auch die Möglichkeiten, die zur Verfügung stehen, um das Ziel zu erreichen. Meistens gibt es keine einfache Lösung, denn nicht alle Probleme sind Addition von zwei positiven ganzen Zahlen. Daher benötigt man Suchverfahren. Hier beschänken wir uns auf die Depth-First Search, Breadth-First Search, Hill Climbing und Best-First Suchverfahren.

\section{Suchalgorithmen}

Wenn man vom Problem und der Darstellung abstrahiert, kann man die Suche nach einer Lösung in einem gerichteten Graph betrachten. Der gerichtete Graph wird nicht gegeben  sondern wird durch Erzeugungsregeln abgeleitet. Der Graph kann auch unendlich groß sein und daher ist die Suche und partielle Erzeugung des Graphen somit verflochten. \\
\\
Unser Suchgraph besteht hier aus Knoten, die die Zustände beschreiben, und Kanten, in Form von Funktionen, die die Nachfolgerknoten berechnet. Außerdem definieren wir eine Anfangssituation und ein Ziel.\\

\bigskip
\begin{tikzpicture}[->,>=stealth',level/.style={sibling distance = 5cm/#1,level distance = 1.5cm}]
\node [arn_n] {S}
    child{ node [arn_n] {}
            child{ node [arn_n] {}
            	child{ node [arn_n] {}}
							child{ node [arn_x] {}}
            }
            child{ node [arn_n] {}
							child{ node [arn_n] {}}
							child{ node [arn_x] {}}
            }
    }
    child{ node [arn_n] {}
            child{ node [arn_n] {}
							child{ node [arn_n] {Z}}
							child{ node [arn_n] {}}
            }
            child{ node [arn_n] {}
							child{ node [arn_n] {}}
							child{ node [arn_x] {}}
            }
    };

    \node [below=5.2cm, align=flush center,text width=8cm]
       {
           Fig1: Graphische Darstellung eines Problems   S: Startknoten, Z: Zielknoten
       };
\end{tikzpicture}

%\subsection{Problemstellung}

%\TODO: Beispiel: Route finding, VLSI Layout, Assembly Sequencing

\section{Uninformierte Suche}
Wir betrachten zunächst die nicht informierte Suche. Hierbei wird bei der Suche nur den Graphen und die Nachfolgerfunktion berücksichtigt, aber keine anderen Informationen über die Knoten, Kanten usw. dürfen verwendet werden.\\

Die Paramenter für unseren Graph sind

\begin{itemize}
  \item Menge der initialen Knoten
  \item Menge der Zielknoten, bzw eindeutige Festlegung der Eigenschaft der Zielknoten
  \item Nachfolgerfunktion N
\end{itemize}

damit lässt sich folgender Algorithmus schreiben:\\

\begin{algorithm}
\caption{General-Search Algorithm}
\begin{algorithmic}[1]
\Function{General-Search}{problem,strategy} \State \textbf{returns} a solution, or failure
\State initialize the search tree using the initial state of $problem$
\Loop \State choose a leaf node for expansion according to $strategy$
  \If {there are no candidates for expansion} failure \EndIf
  \If{the node contains a goal state} the corresponding solution
  \Else{} expand the node and add the resulting nodes to the search tree
  \EndIf
\EndLoop
\EndFunction
\end{algorithmic}
\end{algorithm}


Wir betrachten im folgenden Varianten der blinden Suche, die insbesondere das Wählen des Knotens eindeutig durchführen.

\subsection{Depth-First Search}
\bigskip
Die Depth-First Suche verwendet eine Liste von Knoten und wählt als nächsten zu betrachtenden Knoten dieser Liste. Außerdem werden neue Nachfolger vorne in die Liste eingefügt, was zur Charakteristik führt, dass zunächst in der Tiefe gesucht wird. \\


\begin{algorithm}
\caption{Depth-First Search Algorithm}
\begin{algorithmic}[1]
\Function{Depth-First-Search}{problem} \State \textbf{returns} a solution, or failure
\Function{General-Search}{problem,Enqueue-At-Front}
\EndFunction
\EndFunction
\end{algorithmic}
\end{algorithm}

Die Depth-First Suche eignet sich damit besonders für Suchbäume, deren Äste eine vertretbare Länge nicht überschreiten.\\

\bigskip
\begin{tikzpicture}[->,>=stealth',level 1/.style={sibling distance=50mm},level 2/.style={sibling distance=20mm},level 3/.style={sibling distance=12mm},
%scale=1.2, transform shape
]
\node (nA)[arn_n] {A}
   child { node (nB)[arn_n] {B}
              child { node (nD) [arn_n] {D}
                         child { node (nH) [arn_n] {H} }
                       }
              child {  node (nE) [arn_n] {E}
                         child { node (nI) [arn_n] {I} }
                         child { node (nJ) [arn_n] {J} }
                       }
            }
   child { node (nC) [arn_n] {C}
              child { node (nF) [arn_n] {F}
                         child { node (nK) [arn_n] {K}  }
                         child { node (nL) [arn_n] {L} }
                         child { node (nM) [arn_n] {M} }
                       }
              child {  node (nG) [arn_n] {G} }
             };

  \draw[->,blue,rounded corners,dashed,line width=0.7pt]
    ($(nA) + (-0.4,0.2)$) --
    ($(nB) +(-0.3,0.4)$) --
    ($(nB) +(-0.6,0.0)$) --
    ($(nD)  +(-0.4,0.3)$) --
    ($(nD)  +(-0.5,0.0)$) --
    ($(nH)  +(-0.5,0.0)$) --
    ($(nH)  +(-0.4,-0.35)$) --
    ($(nH)  +(0.0,-0.5)$) --
    ($(nH)  +(0.4,-0.35)$) --
    ($(nH)  +(0.5,0.0)$) --
%    ($(nD)  +(0.45,-0.2)$) --
    ($(nD)  +(0.45,0.0)$) --
    ($(nB)  +(0.0,-0.4)$) --
    ($(nE)  +(-0.45,0.0)$) --
    ($(nI)  +(-0.45,0.0)$) --
    ($(nI)  +(-0.35,-0.35)$) --
    ($(nI)  +(0.0,-0.45)$) --
    ($(nI)  +(0.35,-0.35)$) --
    ($(nI)  +(0.4,0.0)$) --
    ($(nE)  +(0.0,-0.4)$) --
    ($(nJ)  +(-0.45,0.0)$) --
    ($(nJ)  +(-0.35,-0.35)$) --
    ($(nJ)  +(0.0,-0.45)$) --
    ($(nJ)  +(0.35,-0.35)$) --
    ($(nJ)  +(0.45,0.0)$) --
    ($(nE)  +(0.4,0.2)$) --
    ($(nB)  +(0.4,0.0)$) --
    ($(nA)  +(0.0,-0.4)$) --
    ($(nC)  +(-0.4,0.0)$) --
%    ($(nF)  +(-0.6,0.0)$) --
    ($(nK)  +(-0.5,0.1)$) --
    ($(nK)  +(-0.4,-0.35)$) --
    ($(nK)  +(0.0,-0.5)$) --
    ($(nK)  +(0.4,-0.3)$) --
    ($(nF)  +(-0.15,-0.4)$) --
    ($(nL)  +(-0.5,0.0)$) --
    ($(nL)  +(-0.4,-0.35)$) --
    ($(nL)  +(0.0,-0.5)$) --
    ($(nL)  +(0.4,-0.35)$) --
    ($(nL)  +(0.5,0.0)$) --
    ($(nF)  +(0.15,-0.4)$) --
    ($(nM)  +(-0.5,0.0)$) --
    ($(nM)  +(-0.4,-0.35)$) --
    ($(nM)  +(0.0,-0.5)$) --
    ($(nM)  +(0.4,-0.35)$) --
    ($(nM)  +(0.5,0.2)$) --
    ($(nF)  +(0.4,0.0)$) --
    ($(nC)  +(0.0,-0.4)$) --
    ($(nG)  +(-0.5,0.0)$) --
    ($(nG)  +(-0.4,-0.35)$) --
    ($(nG)  +(0.0,-0.5)$) --
    ($(nG)  +(0.4,-0.35)$) --
    ($(nG)  +(0.5,0.1)$) --
    ($(nC) +(0.6,0.0)$) --
    ($(nC) +(0.3,0.4)$) --
    ($(nA) + (0.4,0.2)$);

    \node [below=5.4cm, align=flush center,text width=8cm]
       {
           Fig2: Graphische Darstellung der Depth-First Suche
       };
\end{tikzpicture}

\bigskip

Eine mögliche Implementierung der Depth-First Suche in Prolog ist:\\


\lstinputlisting[language=Prolog]{tiefensuche.pl}

\bigskip

Und in Haskell:\\
\newpage

\lstinputlisting[language=Haskell]{tiefensuche.hs}

\bigskip

Die explizite Speicherung der Pfade sowohl in Haskell als auch in Prolog kostet nicht viel Effizienz. Man kann den Algorithmus auch in imperativen Sprachen implementieren, indem jeder Eintrag einen Knoten mit Zeiger auf den nächsten Nachbarknoten zugeordnet wird. Die Komplexität des Verfahrens (worst-case) für die Zeit ist entsprechend der Anzahl der besuchten Knoten exponentiell in der Tiefe und für den Speicherplatz linear bei fester Verzweigungsrate.\\

Das Problem bei der Depth-First Suche ist, dass der Algorithmus nicht vollständig ist. Wenn der Suchgraph unendlich groß ist, kann die Suche am Ziel vorbeilaufen und für immer im unendlichen langen Pfad laufen.\\

Um dies zu verbeugen kann man eine Tiefenbeschränkung (k) einbauen. Wenn die vorgegebene Tiefenschrank (k) überschriten wird, werden keine Nachfolger dieser Knoten mehr erzeugt. Die Depth-First Suche findet in diesem Fall jeden Zielknoten, der höchstens Tiefe k hat.\\

Wenn der gerichtete Graph kein Baum ist, kann man auch die schon untersuchten Knoten in einer Hash-Tabelle speichern und somit werden die Knoten nicht nochmal untersucht sondern redundant weiterverfolgt.\\

Hierfür ist der Platzbedarf entsprechend der Anzahl der besuchten Knoten und die Berechnungszeit gleich $n*log(n)$ mit n = Anzahl der untersuchten Knoten.\\

\subsubsection{Backtracking}
\bigskip
Die Arbeitsweise der Depth-First Suche ist: Wenn Knoten K keine Nachfolger hat (oder eine Tiefenbeschränkung) überschritten wurde, dann mache weiter mit dem nächsten Bruder von K. Ist der Pfad nicht erfolgreich, führt die Depth-First Suche Backtracking durch. Dies wird als chronologisches Zurücksetzen bezeichnet.\\

Es gibt auch Suchprobleme, bei denen kein Backtracking erforderlich ist (greedy Verfahren ist möglich) zum Beispiel, wenn jeder Knoten noch einen Zielknoten als Nachfolger hat. Die Depth-First Suche reicht dann aus, wenn die Tiefe der Zielknoten in alle Richtungen unterhalb jedes Knotens beschränkt ist. Anderenfalls reicht Depth-First Suche nicht aus, da ein Ast immer ausgesucht werden kann, indem der Zielknoten weiter weg ist.\\

\subsection{Breadth-First Search}
\bigskip
Die Breadth-First Suche verwendet auch eine Liste von Knoten wie bei der Depth-First Suche. Der Unterschied hierbei ist, dass die neuen Nachfolger hinten in die Liste eingefügt werden, was zur Charakteristik führt, dass zunächst in der Breite gesucht wird.\\

\begin{algorithm}
\caption{Breadth-First Search Algorithm}
\begin{algorithmic}[1]
\Function{Breadth-First-Search}{problem} \State \textbf{returns} a solution, or failure
\Function{General-Search}{problem,Enqueue-At-End}
\EndFunction
\EndFunction
\end{algorithmic}
\end{algorithm}

Die Breadth-First Suche untersucht somit ausgehend von Startknoten alle Nachbarknoten. Ist der Zielknoten noch nicht erreicht, werden alle Nachbarknoten der bisher untersuchten Knoten betrachtet.\\

\begin{tikzpicture}[->,>=stealth',level 1/.style={sibling distance=50mm},level 2/.style={sibling distance=20mm},level 3/.style={sibling distance=12mm},
%scale=1, transform shape
]
\node (nA)[arn_n] {A}
   child { node (nB)[arn_n] {B}
              child { node (nD) [arn_n] {D}
                         child { node (nH) [arn_n] {H} }
                       }
              child {  node (nE) [arn_n] {E}
                         child { node (nI) [arn_n] {I} }
                         child { node (nJ) [arn_n] {J} }
                       }
            }
   child { node (nC) [arn_n] {C}
              child { node (nF) [arn_n] {F}
                         child { node (nK) [arn_n] {K}  }
                         child { node (nL) [arn_n] {L} }
                         child { node (nM) [arn_n] {M} }
                       }
              child {  node (nG) [arn_n] {G} }
             };

  \draw[->,blue,rounded corners,dashed,line width=0.7pt]
    ($(nA) + (-0.4,0.2)$) --
    ($(nB) +(-0.3,0.4)$) --
    ($(nB) +(-0.6,0.0)$) --
    ($(nC)  +(+0.3,0.2)$) --
    ($(nC)  +(+0.6,0.0)$) --
    ($(nD)  +(-0.3,0.4)$) --
    ($(nD)  +(-0.4,0.0)$) --
    ($(nE)  +(0.0,0.0)$) --
    ($(nE)  +(0.0,0.0)$) --
    ($(nF)  +(0.0,0.0)$) --
    ($(nF)  +(0.0,0.0)$) --
    ($(nG)  +(0.3,0.2)$) --
    ($(nG)  +(+0.6,0.0)$) --
    ($(nH)  +(-0.3,0.4)$) --
    ($(nH)  +(0.0,0.0)$) --
    ($(nI)  +(0.0,0.0)$) --
    ($(nI)  +(0.0,0.0)$) --
    ($(nJ)  +(0.0,0.0)$) --
    ($(nJ)  +(0.0,0.0)$) --
    ($(nK)  +(0.0,0.0)$) --
    ($(nK)  +(0.0,0.0)$) --
    ($(nL)  +(0.0,0.0)$) --
    ($(nL)  +(0.0,0.0)$) --
    ($(nM)  +(+0.5,0.0)$);

    \node [below=5.2cm, align=flush center,text width=8cm]
       {
           Fig3: Graphische Darstellung der Breadth-First Suche
       };
\end{tikzpicture}

\bigskip

Eine mögliche Implementierung der Breadth-First Suche in Prolog ist:\\

\lstinputlisting[language=Prolog]{breitensuche.pl}

\bigskip

Und in Haskell:\\

\lstinputlisting[language=Haskell]{breitensuche.hs}

\bigskip

Die Vor- und Nachteile der Breadth-First Suche lässt sich wie folgt zusammenfassen:

\begin{itemize}
  \item Die Breadth-First Suche ist vollständig. Das bedeutet, wenn es eine Lösung gibt, wird sie mit Sicherheit gefunden.
  \item Der kürzeste Weg wird gefunden, dafür wird aber viel Speicherplatz benötigt.
  \item Es werden Knoten besucht, die für den optimalen Pfad nicht besucht werden müssten. Damit wird auch der Zeitaufwand erhöht. Dies beträgt nämlich $n+n*log(n)$, für n = Anzahl der Knoten.
\end{itemize}

\subsection{Reverse Search}
\bigskip
Bei der Rückwärtssuche wird von einem (bekannten) Zielknoten ausgegangen in die Richtung des Anfangsknoten.\\

Voraussetzungen für die Rückwärtssuche sind:

\begin{itemize}
  \item Der Zielknoten kann explizit angeben werden(nicht nur eine Eigenschaft, die der Zielknoten erfüllen muss).
  \item Von jedem Knoten ist es möglich, die direkten Vorgänger zu berechnen.
\end{itemize}

Reverse Suche ist aber nur besser als Vorwärtssuche, wenn die Verzweigungsrate in Rückwärtsrichtung kleiner ist als die Verzweigungsrate in Vorwärtsrichtung. Das Problem an der Reverse Suche ist oft, dass die Vorgängerfunktion schwer zu finden ist.

\section{Informierte Suche}

Die Algorithmen, die bis jetzt betrachtet wurden, erzeugen neuen Zuständen und vergleichen sie immer wieder mit dem Zielzustand, bis sie übereinstimmen. Diese Strategie funktioniert, ist aber oft sehr kostenaufwendig. Wir betrachten im folgenden heuristischen Algorithmen.\\

Die Suche wird als $"`heuristische"`$ oder $"`informierte"`$ bezeichnet, wenn man zusätzlich zu den Knoten und zu der Datenstruktur eine Schätzfunktion gibt, die als Schätzung des Abstands zum Zielknoten interpretieren werden kann. Der Zielknoten sollte ein Maximum bzw. Minimum der Schätzfunktion sein.\\

Eine Heuristik ist dann eine Methode, die oft ihren Zweck erreicht, aber nicht mit Sicherheit. Man spricht von heuristischer Suche, wenn die Schätzfunktion in vielen praktisch brauchbaren Fällen die richtige Richtung zu einem Ziel angibt, aber möglicherweise manchmal versagt.\\

Wir suchen dann das Maximum (oder Mininum) einer Knotenfunktion auf einem gerichteten Graphen.\\

\subsection{Hill Climbing}
\bigskip
Der Hill Climbing Suchalgorithm ist auch als Gradientenaufstieg bekannt, da die Suche immer in Richtung der Vergrößerung einer Funktion läuft.\\

Parameter, die notwendig für den Algorithmus sind:

\begin{itemize}
  \item die Menge der initialen Knoten,
  \item die Nachfolgerfunktion,
  \item die Schätzfunktion,
  \item und der Zieltest.
\end{itemize}

Der Algorithmus verhält sich wie die Depth-First Suche, wobei der Nachfolger, der zu expandieren ist, nach der Schätzfunktion ausgesucht wird.\\

\begin{algorithm}
\caption{Hill Climbing Algorithm}
\begin{algorithmic}[1]
\Function{Hill-Climbing}{problem} \State \textbf{returns} a solution state
\INPUT
\Statex $problem$ \Comment Ein Problem
\Statex $current$  \Comment Ein Knoten
\Statex $next$  \Comment Ein Knoten
\State $current \gets Make-Node(Initial-State[problem])$
\Loop
\State $next \gets$ größter Wert aus $current$
\If{$VALUE[next] < VALUE[current]$} \Return current
\EndIf
\State $current \gets next$
\EndLoop
\EndFunction
\end{algorithmic}
\end{algorithm}


Das Problem bei dem Hill Climbing Algorithmus ist, dass er bei lokalen Maxima abbricht. Es ist möglich, in dem Hill-Clinbing Algorithmus Zyklen einzubauen, damit Backtracking durchgeführt wird, aber er bleibt eine zeitlang in den Maxima hängen.\\

Wenn mehrere Nachfolger die gleiche Schätzwerte haben, ist der Weg, den ausgesucht werden soll, nicht eindeutig.\\

Eine mögliche Implementierung der Hill Climbing Suche in Haskell ist:\\

\bigskip

\lstinputlisting[language=Haskell]{hillclimbing.hs}

\bigskip

\subsection{Best-First-Search}
\bigskip
Die Best-First-Suche wählt immer den Knoten aus, der den besten Wert bzgl. der Schätzfunktion hat. Der Knoten wird dann überprüft und, wenn der nicht das Ziel ist, expandiert.\\


\begin{algorithm}
\caption{Best-First-Search Algorithm}
\begin{algorithmic}[1]
\Function{Best-First-Search}{problem,EVAL-FN} \State \textbf{returns} a solution sequence
\INPUT
\Statex $problem$ \Comment Ein Problem
\Statex $Eval-Fn$  \Comment Eine Evaluationsfunktion
\State $Queueing-Fn \gets$ a function that orders nodes by EVAL-FN
\State \textbf{return} GENERAL-SEARCH(problem, Queueing-Fn)
\EndFunction
\end{algorithmic}
\end{algorithm}


Eine Implementierung der Best-First Suche in Haskell ist:\\

\newpage

\lstinputlisting[language=Haskell]{bestfirst.hs}

\bigskip

Die Best-First-Suche ist mit der Depth-First Suche eng verbunden. Der Unterschied ist, dass bei der Best-First Suche den nächsten Knoten, der überprüft und expandiert wird, mithilfe der Schätzfunktion ausgesucht wird. Dabei werden alle Knoten im Stack bewertet und dadurch können lokale Maxima schnell verlassen werden.\\

Wie bei der Depth-First Suche ist die Best-First Suche hier nicht vollständig und die Platzkosten steigern exponentiell in der Tiefe.\\

\newpage
\section{Fazit \& Bewertung}

Zunächst wurden das Suchproblem und der Begriff $"`Suche"`$ erläutert. Die nicht informierte Suchverfahren wurden präsentiert und es wurde gezeigt, dass ein General Search Algorithmus alle Probleme löst, wenn die richtige Strategie ausgesucht wird. \\

Tiefensuche bedeutet, dass man beginnend im Startknoten so weit wie möglich entlang der bestehenden Kanten in die Tiefe geht, ehe man zurückläuft und dann in bislang unbesuchte Teilbäume absteigt.\\

 Breitensuche bedeutet, dass man beginnend im Startknoten alle direkt verbundenen Knoten besucht, bevor die nächst tiefere Ebene überprüft wird.\\

Die Vollständigkeit und die Komplexität der gängigen uninformierten Suchalgorithmen wurden erläutert.\\

Dabei ist klar geworden, dass die Zeit- und Speicherplatzkosten hoch sind. \\

Um die Kosten zu minimieren werden die bekannte Suchverfahren weiterentwickelt. Daraus folgte zum Beispiel die Best-First Suche. Diese ist eine General Search, wobei nur die minimale Anzahl der Knoten berücksichtigt wird.\\  Solche Algorithmen, wobei die Kosten minimiert werden, nennen wir \textbf{greedy Algorithmen}. Der Algorithmus ist aber immer noch nicht optimal.\\

\newpage
\section{Quellen und Literatur}

\begin{thebibliography}{999}
\bibitem {RUENOR} Stuart J. Russel and Peter Norvig, “Artificial Intelligence - A Modern Approach”, Pretince Hall, Englewood Cliffs, New Jersey 2010
\bibitem {BRATKO} Ivan Bratko, “Prolog Programming for Artificial Intelligence”, Addison-Wesley Yugoslavia 1990
\bibitem {SCHABE} R. Schenk and R.P. Abelson, “Scripts, Plans and Knowledge”, International Joint Conference on Artificial Intelligence, 1975
\bibitem {PERSHI} F.C. Pereira and S.M.Schieber, “Prolog and Natural-Language Analysis”, CSLI, 1987
\bibitem {DONLEN} F.M. Donini, M. Lenzerini and others, “The complexity of concept languages”, Inf. Comput., 1997
\bibitem {WEGENE} I. Wegener, “Highlights aus der Informatik”, Springer, Berlin, 1996
\bibitem [MIT] {MIT Open Course - Artificial Intelligence}
 \url{http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/}, Zugriff 28.04.2016
\end{thebibliography}

\end{document}
